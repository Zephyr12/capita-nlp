<!DOCTYPE HTML>


<html>
<head>
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta name="viewport" content="width=device-width, initial-scale=1">

	<!-- Animate.css -->
	<link rel="stylesheet" href="css/animate.css">
	<!-- Icomoon Icon Fonts-->
	<link rel="stylesheet" href="css/icomoon.css">
	<!-- Themify Icons-->
	<link rel="stylesheet" href="css/themify-icons.css">
	<!-- Bootstrap  -->
	<link rel="stylesheet" href="css/bootstrap.css">


	<!-- Magnific Popup -->
	<link rel="stylesheet" href="css/magnific-popup.css">

	<!-- Owl Carousel  -->
	<link rel="stylesheet" href="css/owl.carousel.min.css">
	<link rel="stylesheet" href="css/owl.theme.default.min.css">

	<!-- Theme style  -->
	<link rel="stylesheet" href="css/style.css">

	<!-- Modernizr JS -->
	<script src="js/modernizr-2.6.2.min.js"></script>
	<!-- FOR IE9 below -->
	<!--[if lt IE 9]>
	<script src="js/respond.min.js"></script>
	<![endif]-->

</head>

<body data-spy="scroll" data-target="#toc">



	<div class="gtco-loader"></div>

	<div id="page">
		<nav class="gtco-nav" role="navigation">
			<div class="gtco-container">
				<div class="row">
					<div class="col-md-12 text-center menu-1">
						<ul>
							<li><a href="index.html">Home</a></li>
							<li><a href="requirements.html">Requirements</a></li>
							<li class="active"><a href="research.html">Research</a></li>
							<li><a href="hci.html">HCI</a></li>
							<li><a href="design.html">Design</a></li>
							<li><a href="testing.html">Testing</a></li>
							<li><a href="evaluation.html">Evaluation</a></li>
							<li><a href="management.html">Management</a></li>
						</ul>
					</div>
				</div>

			</div>
		</nav>

		<header id="gtco-header" class="gtco-cover gtco-cover-xs" role="banner" style="background-image:url(images/img_bg_1.jpg);">
			<div class="overlay"></div>
			<div class="gtco-container">
				<div class="row">
					<div class="col-md-12 col-md-offset-0 text-center">
						<div class="display-t">
							<div class="display-tc">
								<h1 class="animate-box" data-animate-effect="fadeInUp">Our Technologies</h1>
								<br><br>
								<h3><font color="white">Find below a list of all the technologies considered in the process of our application.</font></h3>
 									<!-- As we need to consider what possible technologies we might need to use for each
									specific component, our research is conducted to evaluate what alternatives do we have
									and which are most appropriate for our purpose. -->
								</div>
							</div>
						</div>
					</div>
				</div>
			</header>

			<div id="gtco-products" class="gtco-section">
				<div class="row">
					<div class="col-md-8 col-md-offset-2 text-center gtco-heading animate-box">
						<h2>Infrastructure</h2>
						<p>Our system consists of three main components.</p>
							<ul class = "nav headings">
								<font color="black">
									<li>
										<a href="#data-mining-pipelines">Data mining pipeline</a>
									</li>
									<li>
										<a href="#data-transformation">Data Transformation and Feature Engineering</a>
									</li>
									<li>
										<a href="#data-storage">Data Storage</a>
									</li>
								</font>
							</ul>
					</div>
				</div>
			</div>

			<div id="data-mining-pipelines">
				<div class="gtco-container">
					<div class="row animate-box">
						<div class="col-md-12 col-md-offset-0 text-center gtco-heading animate-box">
							<br><br><br><br>
							<h2>Data Processing Pipelines</h2>
							<p>The purpose of the data processing pipeline is to grant us access to social media data, in a useful and accessible format, that is reliably and periodically captured.
								It focuses on capturing assorted social media data including information about specific educational institutions.</p>
							<p> Our information is updated daily, the process could be done more often but it would be counter productive as it comes with unwanted risks, i.e. receiving more data than the system can process, which could result in a system failure.</p>
							<p> The three initial social media sources were <a href="#twitter-pipeline">Twitter</a>, <a href="#facebook-pipeline">Facebook</a> and MumsNet. A lack of content on MumsNet forum forced us to switch to another source and hence, we chose <a href="#scrapy-pipeline">The Student Room</a> - which required the same scraping technology.</p><br>
							</div>
						</div>
					</div>
				</div>

				<div id="gtco-portfolio" class="gtco-section">
					<div class="gtco-container">
						<div class="row">
							<div class="col-md-12 col-md-offset-0 text-center gtco-heading animate-box">
								<h2 id="facebook-pipeline">Facebook SDK for Python</h2>
								<b><h3><font color="white">WHY FACEBOOK API?</font></h3></b>
								<p>
									In order to process data from Facebook, we had a few options: either using the
									<a href="http://facebook-sdk.readthedocs.io/en/latest/index.html">Facebook provided SDK for Python</a>[1], or use other libraries that would ease the work with the API for the developers. Although using other libraries would have made our initial developing process more easy (achieving a working Facebook pipeline), it would have come with risks that we could not take such as unwanted and unknown specific bugs inside that library.
									 Considering our system complexity and the fact that Data Pipeline is our initial component, we decided to use Facebook's GraphAPI, despite its limited feature set.</p>
								<br>
								<b><h3><font color="white">RAISED ISSUES</font></h3></b>
								<p>As GraphAPI recently deprecated certain functionality, we came to realise that, while Facebook did provide support for the Public Feed API (which allowed users access to a realtime feed of user posts), <b>they <a href="https://developers.facebook.com/docs/public_feed/">restricted</a> access to the API to select partners back in 2015</b> - which left us wondering which solution is most appropriate in order to get the desired information from Facebook.</p>

								<b><h3><font color="white">SOLUTION</font></h3></b>
								<p>Even though we could not make use of the public feed of Facebook posts, we could still make <b>search query requests</b> to the Facebook API. As a result, we can have access to Facebook events at any UK Educational Institution. Thus, this pipeline is set up to yield event data (together with other relevant information as concerned university, location, dates).</p>
							</div>
						</div>
					</div>
				</div>

				<div id="gtco-portfolio" class="gtco-section">
					<div class="gtco-container">
						<div class="row">
							<div class="col-md-12 col-md-offset-0 text-center gtco-heading animate-box">
								<h2 id="scrapy-pipeline">Scraping The Student Room with SCRAPY</h2>
								<b><h3><font color="white">WHY SCRAPY?</font></h3></b>
								<p>
									In order to store all the posts relating the Universities in UK that are found on The Student Room forum,
									we had two options:
									<a href="https://scrapy.org/">Scrapy</a>[3]
									or
									<a href="https://www.crummy.com/software/BeautifulSoup/">Beautiful Soup</a>.
								</p>
								<p>
									While BeautifulSoup just parses html documents,
									Scrapy is a <b>full web crawling framework</b> which provides the tools to manage every stage of web
									crawl. Some of these tools are:
									<ol>
										<li>
											Request manager: provides the speed of concurrency without needing to invest time in developing a
											concurrent architecture, as it is all done behind the scenes.
										</li>
										<li>
											Selectors: which are used to parse the HTML documents, in order to find useful information. (BeautifulSoup also does this).
										</li>
										<li>
											Pipelines: once the data is retrieved, it can be <b>passed through various pipelines</b>, which
											serves the purpose of our application.
										</li>
									</ol></p>
									<p>
										We decided that Scrapy would not only be easier to implement, debug, and maintain: but that it would actually faster because of the way it handles concurrency.
									</p>
									<br>
									<b><h3><font color="white">RAISED ISSUES</font></h3></b>
									<p>
										Because Scrapy used it's own pipeline system, integrating it with the pipelines used by the rest of the system proved to be a challenge.
										Scrapy runs more threads in order to be faster and more efficient. But in order to be able to send
										signals between these threads, it needs to run on the main thread in order to read the stop program signal.
									</p>
									<b><h3><font color="white">SOLUTION</font></h3></b>
									<p>
										Looked up the Source Code for Scrapy to understand how it starts its crawler and then modified the
										thread invocation and manually started the scraping process.
									</p>
								</div>
							</div>
						</div>
					</div>

					<div id="gtco-portfolio" class="gtco-section">
						<div class="gtco-container">
							<div class="row">
								<div class="col-md-12 col-md-offset-0 text-center gtco-heading animate-box">
									<h2 id="twitter-pipeline">Twitter Data Pipeline</h2>
									<b>
										<h3>
											<font color="white">
												WHY TWEEPY?
											</font>
										</h3>
									</b>
									<p>
										<a href="http://tweepy.readthedocs.io/en/v3.6.0/">tweepy</a>[4] the industry standard python library for interacting with twitter and it allowed us to use the twitter REST API to it's fullest extent. It's minimal and pythonic nature meant that it was an easy fit for project and took minimal time to integrate into the core Data Pipeline. It raised no issues.
									</p>
								</div>
							</div>
						</div>
					</div>

					<div id="data-transformation">
						<div class="gtco-container">
							<div class="row animate-box">
								<div class="col-md-12 col-md-offset-0 text-center gtco-heading animate-box">
									<br><br><br><br>
									<h2>Data Transformation and Feature Extraction</h2>
									<p>
										These technologies are related to the <b>meaning</b> of the data that is fetched by the data mining
										pipeline. In other words, these are responsible for producing the insight about the data that
										we are collecting.
									</p>
									<p>
										We used <a href="#gensim">gensim</a> for topic modelling and
										<a href="#nltk">nltk</a> for Named-Entity Recogniser(NER) and Sentiment Analysis.
									</p>

									</div>
								</div>
							</div>
						</div>

						<div id="gtco-portfolio" class="gtco-section">
							<div class="gtco-container">
								<div class="row">
									<div class="col-md-12 col-md-offset-0 text-center gtco-heading animate-box">
										<h2 id="gensim">GENSIM</h2>
										<b><h3><font color="white">WHY GENSIM?</font></h3></b>
										<p>
											<a href="https://radimrehurek.com/gensim/">Gensim</a>[5] is a free Python library designed for topic
											modelling. It presents a lot of advantages and seemed to be the most accessible technology
											for our purpose at this level. Some of the useful advantages for our system are:
											<ul>
												<li>Scalability: Gensim can process large, web-scale corpora, using incremental online training
													algorithms. There is no need for the whole input corpus to reside fully in RAM at any one time.
												</li>
													<li>It is Platform Independent: Being pure Python, gensim runs on Linux, Windows and OS X,
														as well as any other platform that supports Python and NumPy.
													</li>
													<li>
														Provides efficient implementations: The core algorithms in gensim use highly
														optimized math routines. Gensim also contains a distributed version of several algorithms,
														intended to speed up processing and retrieval on machine clusters.
													</li>
											</ul>
										</p>


										<br>
										<b><h3><font color="white">RAISED ISSUES</font></h3></b>
										<p>
											Because of the complexity of this advanced process, gensim lda models needed a lot of time
											and data for training - resources that were not available for the scale of our system.
										</p>
										<b><h3><font color="white">SOLUTION</font></h3></b>
										<p>
											We used Google's pre-trained word2vec corpus in order to achieve the necessary output from our system.
										</p>
									</div>
								</div>
							</div>
						</div>

						<div id="gtco-portfolio" class="gtco-section">
							<div class="gtco-container">
								<div class="row">
									<div class="col-md-12 col-md-offset-0 text-center gtco-heading animate-box">
										<h2 id="nltk">NLTK</h2>
										<b><h3><font color="white">WHY NLTK?</font></h3></b>
										<p>
											Our options for language processing were <a href="https://spacy.io/">spaCy</a> and
											<a href="https://www.nltk.org/">nltk</a>[6]. The difference between these two technologies
											is that spaCy represents an Industrial-Strenght Natural Language Processing while NLTK is
											designed to be a good starting point in this area (students, researchers).
										</p>
										<p>
											Moreover, spaCy is faster at Word Tokenization and Part-Of-Speech Tagging, while NLTK is
											faster at Sentence Tokenization - the last one being our system scope. Thus, we considered
											that in our case it is would be the best decision to chose NLTK over spaCy as it provides
											more support and is faster in the area that are mostly concerned about.
										</p>
										<br>
									</div>
								</div>
							</div>
						</div>

						<div id="data-storage">
							<div class="gtco-container">
								<div class="row animate-box">
									<div class="col-md-12 col-md-offset-0 text-center gtco-heading animate-box">
										<br><br><br><br>
										<h2>Data Storage</h2>
										<p>
											<a href="#postgresql">PostgreSQL</a>
										</p>

											<br><br>
										</div>
									</div>
								</div>
							</div>

							<div id="gtco-portfolio" class="gtco-section">
								<div class="gtco-container">
									<div class="row">
										<div class="col-md-12 col-md-offset-0 text-center gtco-heading animate-box">
											<h2 id="postgresql">PostgreSQL</h2>
											<b><h3><font color="white">WHY POSTGRESQL?</font></h3></b>
											<p>
												<a href="https://www.postgresql.org/">Postgresql</a> has the best SQL standard support among open source databases, with support
												for various data types and a large library of built-in data manipulation functions.
											</p>


											<br>
											<b><h3><font color="white">RAISED ISSUES</font></h3></b>
											<p>
												Our client required the system to use Microsoft SQL server. But due to unforeseen circumstances on their side, we only received
												SQL server licenses and keys a week before project hand-in deadline. We decided to use PostgreSQL in the interim as it is mostly compatible with Microsoft SQL Server and migrating from one to the other is a well documented process.
											</p>
											<b><h3><font color="white">SOLUTION</font></h3></b>
											<p>
												We are planning to migrate to SQL Server over the client handover period.
											</p>
										</div>
									</div>
								</div>
							</div>

					</div>



					<footer id="gtco-footer" role="contentinfo">
						<div class="gtco-container">
							<div class="row copyright">
								<div class="col-md-12">
									<p class="pull-left">
										<h2>References:</h2>
										<font color="black">
										<li>[1] Facebook SDK for Python Documentation (Version 2.0.0). Available at: http://facebook-sdk.readthedocs.io/en/latest/index.html (Acceessed: 22 March 2018)</li>
										<li>[2] Facebook Documentation Changelog (2018). Available at: https://developers.facebook.com/docs/graph-api/changelog/ (Accessed: 20 March 2018)</li>
										<li>[3] Scrapy Documentation (Version 1.5). Available at: https://docs.scrapy.org/en/latest/ (Accessed: 22 March 2018)</li>
										<li>[4] Tweepy Documentation (Version 3.6.0). Available at: http://tweepy.readthedocs.io/en/v3.6.0/ (Accessed: 22 March 2018)</li>
										<li>[5] Gensim API References (Mar 2018). Available at: https://radimrehurek.com/gensim/apiref.html (Accessed: 22 March 2018)</li>
										<li>[6] NLTK Package Documentation (Version 3.2.4). Available at: https://www.nltk.org/api/nltk.html (Accessed: 22 March 2018)</li>
									</font>
									</p>
								</div>
							</div>
						</div>
					</footer>
				</div>

						<div class="gototop js-top">
							<a href="#" class="js-gotop"><i class="icon-arrow-up"></i></a>
						</div>

						<!-- jQuery -->
						<script src="js/jquery.min.js"></script>
						<!-- jQuery Easing -->
						<script src="js/jquery.easing.1.3.js"></script>
						<!-- Bootstrap -->
						<script src="js/bootstrap.min.js"></script>

						<!-- Waypoints -->
						<script src="js/jquery.waypoints.min.js"></script>
						<!-- Carousel -->
						<script src="js/owl.carousel.min.js"></script>
						<!-- countTo -->
						<script src="js/jquery.countTo.js"></script>
						<!-- Magnific Popup -->
						<script src="js/jquery.magnific-popup.min.js"></script>
						<script src="js/magnific-popup-options.js"></script>
						<!-- Main -->
						<script src="js/main.js"></script>

					</body>
					</html>
