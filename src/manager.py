import csv
import fb
import nlp
import models
from db import MyDB
import sys
from pipes import Source, Processor, Writer
import psycopg2.extras


def recreate_tables(db):
    db.drop_table("schools")
    db.drop_table("post")
    db.drop_table("topic")

    db.create_table(
            "schools",
            {
                "establishment_name": "text PRIMARY KEY",
                "URN": "integer NOT NULL",
                "postcode": "text NOT NULL",
                "type_of_establishment": "text NOT NULL",
                "phase_of_education": "text NOT NULL"
                }
    )

    db.create_table(
            "topic",
            {
                "id": "int GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY",
                "topic_description": "text"
                }
            )

    db.create_table(
            "post",
            {
                "post_id": "int GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY",
                "timestamp": "datetime NOT NULL",
                "raw_text": "text", "sentiment": "real NOT NULL",
                "school_id": "text references schools(establishment_name)",
                "topic_id": "integer references topic(id)"
                }
            )


def load_schools_table(db):
    data_table = csv.DictReader(open("data/schools.csv"))
    for row in data_table:
        db.add_row("schools", {"URN": row["URN"] , "establishment_name": row["EstablishmentName"], "postcode": row["Postcode"], "type_of_establishment": row["TypeOfEstablishment (name)"], "phase_of_education": row["PhaseOfEducation (name)"]})

def load_fb_posts(db):
    classifier = nlp.ner_classifier(["University College London"])
    src = Source([
                    Processor(
                            [Processor([
                                Writer(lambda x: db.add_row("post", x))],
                                classifier
                                )],
                            nlp.sentiment())],
                    fb.run
                )
    src.start()

def retopic(db):
    import topics
    unassigned_posts = db.select("select * from post where topic_id is null")
    for topic in topics.split_raw(unassigned_posts, n=10):
        if topic:
            text = topic[0]["raw_text"][:125] + "..."
            topic_id = db.add_row("topic", {"topic_description": text}, returning="id")[0]
            for post in topic:
                db.update_row("post", post["post_id"], {"topic_id": topic_id}, id_field="post_id")


def data_pipeline(db):
    pass

def main():
    db = MyDB("dbname=capita user=amartya password=test")
    if sys.argv[1] == "load_schools":
        load_schools_table(db)
    elif sys.argv[1] == "recreate_tables":
        recreate_tables(db)
    elif sys.argv[1] == "load_fb":
        load_fb_posts(db)
    elif sys.argv[1] == "retopic":
        retopic(db)
    else:
        print("error invalid command")


if __name__ == '__main__':
    main()
